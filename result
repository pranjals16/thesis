IMPORTANT
average of shuffled and not shuffled sentence vectors
92.14 logistic c=3.3; without rnnlm 
92.22 linear SVM c=0.29 without rnnlm 
92.71 c=4.5 rnnlm
https://groups.google.com/forum/#!msg/word2vec-toolkit/Q49FIrNOQRo/CJLWzmr0LaUJ
-----------------------------------------


random forest: 280 trees
84.14
svm: linear (300 context;min count=20)
87.05
Naive Bayes
75.95
merged with Wiki trained(300 dim wiki trained context5)-svm
88.60
Logistic Regression with l1 penalty
86.90
k-nn:20
76.76
---------------------------------------------------------------------
Hindi

78.0% 50-fold cross validation (350+350 product review;context = 5 downsampling = 1e-5 word_count=1)
79.62% 20-fold cross validation (iitb movie review;context = 5 downsampling = 1e-5 word_count=1,feature=300) better than paper : a fall-back strategy


Merged word vectors with tf-idf
------------------
89.52% 20-fold cross validation (iitb movie review;context = 6 downsampling = 1e-3 word_count=1,feature=500) better than paper : a fall-back strategy
90.86% 20-fold cross validation (350+350 product review;context = 6 downsampling = 1e-3 word_count=1)


with stop words removed(vectorizer = TfidfVectorizer(tokenizer=tokenize,use_idf=True,max_df=0.3,min_df=0.0001,strip_accents='unicode'))
------------------------
89.97% 20-fold cross validation (iitb movie review;context = 6 downsampling = 1e-3 word_count=1,feature=500) better than paper : a fall-back strategy
91.14% 20-fold cross validation (350+350 product review;context = 6 downsampling = 1e-3 word_count=1)

-----

tf-idf+BOW results
------------------------------------------------------------
with pos+neg together idf includes tf-idf features
89.71 : IIIT
85.90 : IITB
92.89:IIIT:600,6,1e-4;svm(C=0.9)40-fold
90.30:IITB:500,7,1e-4;svm(C=0.8)40-fold

with separate idf_scores includes tf-idf features
93.71: IIIT
90.13: IITB 600 features


wihtout tf-idf features: pure weighted pos+neg separate average
92.86: IIIT
88.17: IITB  600 features

Doc2Vec
IITB:89.17;800,8,1e-4;svm(C=0.9)20-fold with feature engineering
IITB:79.17;800,8,1e-4;svm(C=0.6)20-fold
IIIT:86.86;800,7,1e-5;svm(C=0.8)20-fold
IIIT: 90.86;800,7,1e-5;svm(C=0.8)20-fold with feature engineering
---------------------------------------------------------------

parsed amazon dataset

Average Word Vectors
88.39: MP3  500 features context=10 (NE=10) cbow
88.98: MP3  500 features context=10 (NE=10) sg
88.64: MP3  500 features context=5 (NE=10) sg
88.69: MP3  500 features context=6 (NE=10) sg
89.02: MP3  500 features context=7 (NE=10) sg
88.74: MP3  500 features context=8 (NE=10) sg
89.02: MP3  500 features context=9 (NE=10) sg
89.41: Electronics  500 features context=10 sg
91.40  Electronics with docvec linear svm c=0.1
92.17  Electronics with docvec+word2vec svm c=0.1
92.91 with docvec and RNNLM
90.69: Watches 500 features context=10 cbow
91.15: Watches 500 features context=10 sg
90.90: Watches 500 features context=5 sg
90.96: Watches 500 features context=6 sg
91.19: Watches 500 features context=7 sg
90.99: Watches 500 features context=8 sg
91.17: Watches 500 features context=9 sg

Trip Advisor Dataset
91.57% accuracy: 600 context=10

--------------------------------------------------------------------------------
Movie Review Dataset(Mine)
Doc2Vec
------
74.57
88.07: with feature engineering

Without Feature Engineering:
75.86:500,5
76.43:600,5
77.44:600,6(c=0.9)

With Feature Engineering:
89.51:500,5
90.37: 600 select_k_best
91.53: C=2.5 new weighted of probability
78.61: PCA 50
66.67: LDA

92.53 with grid search select_k_best

--------------------------------------------------------------------------------
IMDB DocVec

1) PvDm: 72.52
2) PvDBOW: 74.77
3) 92.93 with logistic
4) 92.88 svm
5) 93.07 grid search
6) 93.33 rbf kernel svm

Word2vec+tfidf: 89.03%

--------------------------------------------------------
Word2vec: 88.42(pure average with varying C in SVM Linear)
Word2vec: 88.41 (weighted average with varying C in SVM Linear)
------------------------------------------------------------

docvec+word2vec
1) 93.09 logistic 100features_10minwords_10context
2) 92.98 svm 100features_10minwords_10context
3) 93.18 svm 200features_10minwords_10context linear
4) 93.17 graded idf 2.0 logistic 
5) 93.16 graded idf 2.5 logistic 
6) 93.16 graded idf 2.8 logistic 
7) 93.22     svm with graded idf at 3.0
8) 93.12     logistic with graded idf at 4.0
9) 93.03     logistic with graded idf at 5.0 l2
10) 93.00     logistic with graded idf at 6.0 l2

docvec+word2vec+wiki
1) 93.09 logistic wiki context old 200features_10minwords_10context
2) 93.18 logistic wiki context 10 200features_10minwords_10context C=1.6
3) 93.03 logistic wiki context 5 200features_10minwords_10context
4) 93.18 with weighted logistic wiki context 10 200features_10minwords_10context C=1.6
------------------
wordvec+docvec+rnnlm
93.468 with RNNLM+docvec
93.70  (c=6.5,100features+100) 50 nodes in RNNLM

93.57: word+doc+wiki+rnnlm hidden=50
93.93 word+doc+tfidf+rnnlm c=2.1 hidden=50
94.19 word+doc+tfidf+rnnlm c=8.5 without stop words hidden=50

word+doc+tfidf
93.448 ngram=1,2;features=25000
93.456 ngram=1,2;features=20000
93.64 ngram=1,2;features=15000 (C=0.2 LinearSVC)
93.91 ngram=1,2;features=15000 stop_words=false svm C=0.33
93.83 ngram=1,2;features=15000 stop_words=false logistic l2 c=4.3
93.89 graded idf 2.0 svm c=0.36
93.87 graded idf 2.5 svm c=0.36
93.86 graded idf 2.8 svm c=0.36
93.86 graded idf 3.0 logistic l2 c=4.1
93.83 graded idf 4.0 logistic l2 c=3.9
93.75 graded idf 5.0 logistic l2 c=0.3
93.68 graded idf 6.0 svm l2 c=4.1

93.88 graded idf 3.0 svm c=0.34

word+doc+wiki+tfidf
93.55 linear svm c=0.3

normal weighted word: 88.42
graded weighted 2.0 : 89.56 svm
weighted word+ doc: 93.19 linear svm
------------------

Graded+docvec
-----
with stopwords
logistic l1:3.5, 88.14
logistic l2:9.1, 87.52
svm: 6.5, 88.21

without stopwords
logistic l1:3.5, 88.27
logistic l2:9.1, 88.42
svm: 1.2, 88.42

Graded+docvec+tfidf
-----
with stopwords
93.84

without stopwords
93.91

idf_stats:
min=1.0081
max=11.4143

0
45
113
273
654
1450
2956
5311
9015
13315
22628
24853

2,2.5,2.8,3.0(with stop words removed)

updates in thesis:

skipgram cbow image
result of 93.24 to 93.18


Updates in 
20,43,44
