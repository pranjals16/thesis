\cleardoublepage

\begin{center}
	\huge{\textbf{Abstract}}
\end{center}

In recent years, distributional semantics or vector models for words and documents have been proposed to capture both the syntactic and semantic similarities. Since these are language free models and can be obtained in an unsupervised manner, they are of interest for under-resourced languages such as Hindi and many more other languages. 
Language free models are generic and, in recent years, have developed the capability of performing various NLP tasks efficiently. Their capability of being invariant for different languages has attracted the attention of various researchers. We have developed such a language free model using distributional semantics and traditional language representation methods and achieved better results than language models.

We test the efficacy of such an approach for many things and especially Hindi, first by a subjective overview which shows that a reasonable measure of word similarity seems to be captured quite easily.  We then apply it to the sentiment analysis for many English review datasets including IMDB and two small Hindi databases from earlier work and our own built dataset of Hindi movie reviews. 
We have gone a step ahead with document vectors and built new features merged with various models to achieve state-of-the art results in sentiment classification on classical IMDB movie review dataset achieving an accuracy of 94.19\%(improvement of 1.61\% over previous best). We also implement an ensemble model which boosts our accuracy by about 0.5\% using recurrent neural network.

We demonstrate the language free aspects by developing a huge increment on results for Hindi. We also propose that dimensionality reduction techniques such as ANOVA-F and PCA are of great help to reduce noise and boost accuracy of our models.

In order to handle larger strings from the word vectors, several methods - additive, multiplicative, or tensor neural models, have been proposed.  Here we propose weighted additive average technique, which results in an impressive accuracy gain on state of the art by 12\% (from 80\%) for two hindi review datasets.  The results suggest that it may be worthwhile to explore such methods further for Indian languages.\\

